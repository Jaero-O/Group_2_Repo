{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# -------------------------------\n",
    "# GPIO Setup\n",
    "# -------------------------------\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "SCAN_BUTTON = 17\n",
    "GPIO.setup(SCAN_BUTTON, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "\n",
    "# -------------------------------\n",
    "# ORB + Matcher Setup\n",
    "# -------------------------------\n",
    "orb = cv2.ORB_create(800)  # reduced features for speed\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "MAX_FRAME_WIDTH = 600  # downsize for speed\n",
    "\n",
    "def preprocess(frame, width=MAX_FRAME_WIDTH):\n",
    "    h, w = frame.shape[:2]\n",
    "    if w > width:\n",
    "        new_h = int(h * width / w)\n",
    "        frame = cv2.resize(frame, (width, new_h), interpolation=cv2.INTER_AREA)\n",
    "    return frame\n",
    "\n",
    "def linear_blend(target, warped, mask_warped):\n",
    "    overlap = (mask_warped.astype(np.uint8) & (cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)>0).astype(np.uint8))\n",
    "    if overlap.sum() == 0:\n",
    "        target[mask_warped==1] = warped[mask_warped==1]\n",
    "        return target\n",
    "    dist = cv2.distanceTransform((overlap==0).astype(np.uint8), cv2.DIST_L2, 5)\n",
    "    maxd = dist.max() if dist.max()>0 else 1.0\n",
    "    alpha = np.clip(dist / maxd, 0.0, 1.0)[...,None]\n",
    "    mask = mask_warped.astype(bool)\n",
    "    target[mask] = (warped[mask].astype(np.float32) * (1-alpha[mask]) + target[mask].astype(np.float32) * alpha[mask]).astype(np.uint8)\n",
    "    return target\n",
    "\n",
    "def stitch_frames(frame_sequence):\n",
    "    first = preprocess(frame_sequence[0])\n",
    "    H, W = first.shape[:2]\n",
    "    big_canvas = np.zeros((H*4, W*3, 3), dtype=np.uint8)\n",
    "    big_mask = np.zeros((H*4, W*3), dtype=np.uint8)\n",
    "\n",
    "    y0 = 10\n",
    "    x0 = (big_canvas.shape[1] - W)//2\n",
    "    big_canvas[y0:y0+H, x0:x0+W] = first\n",
    "    big_mask[y0:y0+H, x0:x0+W] = 255\n",
    "\n",
    "    prev_kp, prev_des = orb.detectAndCompute(cv2.cvtColor(first, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "    for raw in frame_sequence[1:]:\n",
    "        frame = preprocess(raw)\n",
    "        gframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = orb.detectAndCompute(gframe, None)\n",
    "        if des is None or prev_des is None:\n",
    "            continue\n",
    "        matches = bf.match(des, prev_des)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)[:100]\n",
    "\n",
    "        if len(matches) < 8:\n",
    "            continue\n",
    "\n",
    "        src_pts = np.float32([ kp[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ prev_kp[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "        Hmat, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        if Hmat is None:\n",
    "            continue\n",
    "\n",
    "        warped = cv2.warpPerspective(frame, Hmat, (big_canvas.shape[1], big_canvas.shape[0]))\n",
    "        warped_gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "        warped_mask = (warped_gray > 10).astype(np.uint8)\n",
    "\n",
    "        big_canvas = linear_blend(big_canvas, warped, warped_mask)\n",
    "        big_mask = np.clip(big_mask + warped_mask*255, 0, 255)\n",
    "\n",
    "        prev_kp, prev_des = kp, des\n",
    "\n",
    "    ys, xs = np.where(big_mask>0)\n",
    "    if ys.size == 0:\n",
    "        return big_canvas\n",
    "    miny, maxy = ys.min(), ys.max()\n",
    "    minx, maxx = xs.min(), xs.max()\n",
    "    return big_canvas[miny:maxy+1, minx:maxx+1]\n",
    "\n",
    "# -------------------------------\n",
    "# TFLite Setup\n",
    "# -------------------------------\n",
    "interpreter = tflite.Interpreter(model_path=\"mango_leaf_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "class_names = [\"Healthy\", \"Anthracnose\", \"OtherDisease\"]  # replace with your classes\n",
    "\n",
    "def classify_leaf(img):\n",
    "    h, w = input_details[0]['shape'][1], input_details[0]['shape'][2]\n",
    "    img_resized = cv2.resize(img, (w, h))\n",
    "    img_resized = img_resized.astype(np.float32) / 255.0\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], img_resized)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    class_idx = np.argmax(output_data)\n",
    "    confidence = output_data[class_idx]\n",
    "    return class_idx, confidence\n",
    "\n",
    "# Optional severity (example)\n",
    "def estimate_severity(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "    diseased_pixels = np.sum(mask > 0)\n",
    "    total_pixels = mask.size\n",
    "    return (diseased_pixels / total_pixels) * 100\n",
    "\n",
    "# -------------------------------\n",
    "# Scan Function\n",
    "# -------------------------------\n",
    "def scan_leaf():\n",
    "    print(\"üì∏ Scanning started...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % 5 == 0:\n",
    "            frames.append(frame)\n",
    "            print(f\"Captured frame {len(frames)}\")\n",
    "        frame_count += 1\n",
    "\n",
    "        if GPIO.input(SCAN_BUTTON) == GPIO.HIGH:  # button released\n",
    "            break\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(frames) > 1:\n",
    "        stitched = stitch_frames(frames)\n",
    "        cv2.imwrite(\"stitched_leaf.png\", stitched)\n",
    "        print(\"üåø Stitched leaf saved as stitched_leaf.png\")\n",
    "\n",
    "        # Classification\n",
    "        class_idx, confidence = classify_leaf(stitched)\n",
    "        print(f\"Disease: {class_names[class_idx]}, Confidence: {confidence*100:.2f}%\")\n",
    "\n",
    "        # Severity\n",
    "        severity = estimate_severity(stitched)\n",
    "        print(f\"Severity: {severity:.2f}%\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Not enough frames for stitching.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Main Loop\n",
    "# -------------------------------\n",
    "try:\n",
    "    while True:\n",
    "        if GPIO.input(SCAN_BUTTON) == GPIO.LOW:  # button pressed\n",
    "            scan_leaf()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    GPIO.cleanup()\n",
    "    print(\"\\nüëã Exiting\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
